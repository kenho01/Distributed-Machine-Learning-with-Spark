{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./spark_mllib/lib/python3.12/site-packages (3.5.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./spark_mllib/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Spark MLlib\") \\\n",
    "        .config('spark.ui.port', '4040') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").load(\"ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: timestamp (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- flat_type: string (nullable = true)\n",
      " |-- block: string (nullable = true)\n",
      " |-- street_name: string (nullable = true)\n",
      " |-- storey_range: string (nullable = true)\n",
      " |-- floor_area_sqm: double (nullable = true)\n",
      " |-- flat_model: string (nullable = true)\n",
      " |-- lease_commence_date: integer (nullable = true)\n",
      " |-- remaining_lease: string (nullable = true)\n",
      " |-- resale_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "|              month|      town|flat_type|block|      street_name|storey_range|floor_area_sqm|    flat_model|lease_commence_date|   remaining_lease|resale_price|\n",
      "+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   2 ROOM|  406|ANG MO KIO AVE 10|    10 TO 12|          44.0|      Improved|               1979|61 years 04 months|    232000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  108| ANG MO KIO AVE 4|    01 TO 03|          67.0|New Generation|               1978|60 years 07 months|    250000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  602| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|62 years 05 months|    262000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  465|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1980| 62 years 01 month|    265000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  601| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|62 years 05 months|    265000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  150| ANG MO KIO AVE 5|    01 TO 03|          68.0|New Generation|               1981|          63 years|    275000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|61 years 06 months|    280000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  218| ANG MO KIO AVE 1|    04 TO 06|          67.0|New Generation|               1976|58 years 04 months|    285000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|61 years 06 months|    285000.0|\n",
      "|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  571| ANG MO KIO AVE 3|    01 TO 03|          67.0|New Generation|               1979|61 years 04 months|    285000.0|\n",
      "+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188947"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df = df.withColumn('id', monotonically_increasing_id())\n",
    "df = df[['id'] + df.columns[:-1]]\n",
    "# df.show(10)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "| id|              month|      town|flat_type|block|      street_name|storey_range|floor_area_sqm|    flat_model|lease_commence_date|   remaining_lease|resale_price|\n",
      "+---+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "|  0|2017-01-01 00:00:00|ANG MO KIO|   2 ROOM|  406|ANG MO KIO AVE 10|    10 TO 12|          44.0|      Improved|               1979|61 years 04 months|    232000.0|\n",
      "|  1|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  108| ANG MO KIO AVE 4|    01 TO 03|          67.0|New Generation|               1978|60 years 07 months|    250000.0|\n",
      "|  2|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  602| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|62 years 05 months|    262000.0|\n",
      "|  3|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  465|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1980| 62 years 01 month|    265000.0|\n",
      "|  4|2017-01-01 00:00:00|ANG MO KIO|   3 ROOM|  601| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|62 years 05 months|    265000.0|\n",
      "+---+-------------------+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col, expr, coalesce, lit\n",
    "\n",
    "# Data transformation\n",
    "df = df.withColumn(\"remaining_lease_years\", regexp_extract(col(\"remaining_lease\"), r\"(\\d+) years\", 1).cast(\"int\")) \\\n",
    "  .withColumn(\"remaining_lease_months\", regexp_extract(col(\"remaining_lease\"), r\"(\\d+) month\", 1).cast(\"int\"))\n",
    "\n",
    "df = df.withColumn(\"remaining_lease_months\", coalesce(col(\"remaining_lease_months\"), lit(0)))\n",
    "\n",
    "df = df.withColumn(\"remaining_lease_in_months\", expr(\"remaining_lease_years * 12 + remaining_lease_months\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('month', 'block', 'street_name', 'lease_commence_date', 'remaining_lease', 'remaining_lease_years', 'remaining_lease_months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "|  0|ANG MO KIO|   2 ROOM|    10 TO 12|          44.0|      Improved|    232000.0|                      736|\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|\n",
      "|  3|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|    265000.0|                      745|\n",
      "|  4|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    265000.0|                      749|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variables used for training: \n",
    "    # Categorical: town, flat_type, storey_range, floor_area_sql, flat_model\n",
    "    # Numerical: floor_area_sql, remaining_lease_in_months\n",
    "# Predict resale_price\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[id: bigint, town: string, flat_type: string, storey_range: string, floor_area_sqm: double, flat_model: string, resale_price: double, remaining_lease_in_months: int],\n",
       " DataFrame[id: bigint, town: string, flat_type: string, storey_range: string, floor_area_sqm: double, flat_model: string, resale_price: double, remaining_lease_in_months: int])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['floor_area_sqm', 'remaining_lease_in_months']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features_lst = train.columns\n",
    "numerical_features_lst.remove('id')\n",
    "numerical_features_lst.remove('town')\n",
    "numerical_features_lst.remove('flat_type')\n",
    "numerical_features_lst.remove('storey_range')\n",
    "numerical_features_lst.remove('flat_model')\n",
    "numerical_features_lst.remove('resale_price')\n",
    "numerical_features_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=numerical_features_lst, outputCols=numerical_features_lst)\n",
    "imputer = imputer.fit(train)\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler \n",
    "numerical_vector_assembler = VectorAssembler(inputCols=numerical_features_lst, outputCol='numerical_feature_vector')\n",
    "train = numerical_vector_assembler.transform(train)\n",
    "test = numerical_vector_assembler.transform(test)\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|           [-1.2519466170961...|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|           [-1.2103596230898...|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "# Normal distribution\n",
    "scaler = StandardScaler(inputCol='numerical_feature_vector', outputCol='scaled_numerical_feature_vector', withStd=True, withMean=True)\n",
    "scaler = scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(scaled_numerical_feature_vector=DenseVector([-1.2519, -0.9974])),\n",
       " Row(scaled_numerical_feature_vector=DenseVector([-1.2519, -0.8666])),\n",
       " Row(scaled_numerical_feature_vector=DenseVector([-1.2104, -0.8249])),\n",
       " Row(scaled_numerical_feature_vector=DenseVector([-1.2104, -0.932])),\n",
       " Row(scaled_numerical_feature_vector=DenseVector([-1.2519, -0.9439]))]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('scaled_numerical_feature_vector').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['town', 'flat_type', 'storey_range', 'flat_model']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_lst = train.columns\n",
    "categorical_features_lst.remove('id')\n",
    "categorical_features_lst.remove('floor_area_sqm')\n",
    "categorical_features_lst.remove('remaining_lease_in_months')\n",
    "categorical_features_lst.remove('resale_price')\n",
    "categorical_features_lst.remove('numerical_feature_vector')\n",
    "categorical_features_lst.remove('scaled_numerical_feature_vector')\n",
    "categorical_features_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|town_index|flat_type_index|storey_range_index|flat_model_index|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|           [-1.2103596230898...|       9.0|            2.0|               3.0|             2.0|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# Convert categorical variable to a particular value\n",
    "# Not sure why using a Pipeline doesn't work -> Workaround is to do manually since categorically variable is quite small\n",
    "indexer = StringIndexer(inputCol='town', outputCol='town_index')\n",
    "indexer = indexer.fit(train)\n",
    "train = indexer.transform(train)\n",
    "test = indexer.transform(test)\n",
    "\n",
    "indexer = StringIndexer(inputCol='flat_type', outputCol='flat_type_index')\n",
    "indexer = indexer.fit(train)\n",
    "train = indexer.transform(train)\n",
    "test = indexer.transform(test)\n",
    "\n",
    "indexer = StringIndexer(inputCol='storey_range', outputCol='storey_range_index')\n",
    "indexer = indexer.fit(train)\n",
    "train = indexer.transform(train)\n",
    "test = indexer.transform(test)\n",
    "\n",
    "indexer = StringIndexer(inputCol='flat_model', outputCol='flat_model_index')\n",
    "indexer = indexer.fit(train)\n",
    "train = indexer.transform(train)\n",
    "test = indexer.transform(test)\n",
    "\n",
    "train.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Row(flat_model_index=0.0),\n",
       " Row(flat_model_index=1.0),\n",
       " Row(flat_model_index=2.0),\n",
       " Row(flat_model_index=3.0),\n",
       " Row(flat_model_index=4.0),\n",
       " Row(flat_model_index=5.0),\n",
       " Row(flat_model_index=6.0),\n",
       " Row(flat_model_index=7.0),\n",
       " Row(flat_model_index=8.0),\n",
       " Row(flat_model_index=9.0),\n",
       " Row(flat_model_index=10.0),\n",
       " Row(flat_model_index=11.0),\n",
       " Row(flat_model_index=12.0),\n",
       " Row(flat_model_index=13.0),\n",
       " Row(flat_model_index=14.0),\n",
       " Row(flat_model_index=15.0),\n",
       " Row(flat_model_index=16.0),\n",
       " Row(flat_model_index=17.0),\n",
       " Row(flat_model_index=18.0),\n",
       " Row(flat_model_index=19.0),\n",
       " Row(flat_model_index=20.0)}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.select('flat_model_index').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|town_index|flat_type_index|storey_range_index|flat_model_index|  town_one_hot|flat_type_one_hot|storey_range_one_hot|flat_model_one_hot|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|           [-1.2103596230898...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(inputCol='town_index', outputCol='town_one_hot')\n",
    "one_hot_encoder = one_hot_encoder.fit(train)\n",
    "train = one_hot_encoder.transform(train)\n",
    "test = one_hot_encoder.transform(test)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCol='flat_type_index', outputCol='flat_type_one_hot')\n",
    "one_hot_encoder = one_hot_encoder.fit(train)\n",
    "train = one_hot_encoder.transform(train)\n",
    "test = one_hot_encoder.transform(test)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCol='storey_range_index', outputCol='storey_range_one_hot')\n",
    "one_hot_encoder = one_hot_encoder.fit(train)\n",
    "train = one_hot_encoder.transform(train)\n",
    "test = one_hot_encoder.transform(test)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(inputCol='flat_model_index', outputCol='flat_model_one_hot')\n",
    "one_hot_encoder = one_hot_encoder.fit(train)\n",
    "train = one_hot_encoder.transform(train)\n",
    "test = one_hot_encoder.transform(test)\n",
    "\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|town_index|flat_type_index|storey_range_index|flat_model_index|  town_one_hot|flat_type_one_hot|storey_range_one_hot|flat_model_one_hot|final_feature_vector|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|           [-1.2103596230898...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine numerical and categorical\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['scaled_numerical_feature_vector', 'town_one_hot', 'flat_type_one_hot', 'storey_range_one_hot', 'flat_model_one_hot'],\n",
    "                            outputCol='final_feature_vector')\n",
    "train = assembler.transform(train)\n",
    "test = assembler.transform(test)\n",
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(final_feature_vector=SparseVector(69, {0: -1.2519, 1: -0.9974, 11: 1.0, 29: 1.0, 36: 1.0, 51: 1.0})),\n",
       " Row(final_feature_vector=SparseVector(69, {0: -1.2519, 1: -0.8666, 11: 1.0, 29: 1.0, 36: 1.0, 51: 1.0})),\n",
       " Row(final_feature_vector=SparseVector(69, {0: -1.2104, 1: -0.8249, 11: 1.0, 29: 1.0, 36: 1.0, 51: 1.0}))]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('final_feature_vector').take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_ea2e8f85e9c9"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='final_feature_vector', \n",
    "                      labelCol='resale_price')\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/07 12:43:01 WARN Instrumentation: [9c5f1c4e] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "lr = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|town_index|flat_type_index|storey_range_index|flat_model_index|  town_one_hot|flat_type_one_hot|storey_range_one_hot|flat_model_one_hot|final_feature_vector|predicted_resale_price|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "|  1|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    250000.0|                      727|            [67.0,727.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|    326206.74278083094|\n",
      "|  2|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    262000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|    333581.70748555695|\n",
      "|  5|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|    275000.0|                      756|            [68.0,756.0]|           [-1.2103596230898...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|     338908.7852119289|\n",
      "|  6|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|    280000.0|                      738|            [68.0,738.0]|           [-1.2103596230898...|       9.0|            2.0|               0.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[0],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,33...|     350079.0737632893|\n",
      "|  9|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    285000.0|                      736|            [67.0,736.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|    329223.77379640075|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train_df = lr.transform(train).withColumnRenamed('prediction', 'predicted_resale_price')\n",
    "pred_train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "| id|      town|flat_type|storey_range|floor_area_sqm|    flat_model|resale_price|remaining_lease_in_months|numerical_feature_vector|scaled_numerical_feature_vector|town_index|flat_type_index|storey_range_index|flat_model_index|  town_one_hot|flat_type_one_hot|storey_range_one_hot|flat_model_one_hot|final_feature_vector|predicted_resale_price|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "|  0|ANG MO KIO|   2 ROOM|    10 TO 12|          44.0|      Improved|    232000.0|                      736|            [44.0,736.0]|           [-2.2084474792397...|       9.0|            4.0|               2.0|             1.0|(25,[9],[1.0])|    (6,[4],[1.0])|      (16,[2],[1.0])|    (20,[1],[1.0])|(69,[0,1,11,31,35...|    247241.81254870223|\n",
      "|  3|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|    265000.0|                      745|            [68.0,745.0]|           [-1.2103596230898...|       9.0|            2.0|               0.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[0],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,33...|    352425.65344206576|\n",
      "|  4|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|    265000.0|                      749|            [67.0,749.0]|           [-1.2519466170961...|       9.0|            2.0|               3.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[3],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,36...|    333581.70748555695|\n",
      "|  7|ANG MO KIO|   3 ROOM|    04 TO 06|          67.0|New Generation|    285000.0|                      700|            [67.0,700.0]|           [-1.2519466170961...|       9.0|            2.0|               0.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[0],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,33...|     334360.0003166217|\n",
      "|  8|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|    285000.0|                      738|            [68.0,738.0]|           [-1.2103596230898...|       9.0|            2.0|               0.0|             2.0|(25,[9],[1.0])|    (6,[2],[1.0])|      (16,[0],[1.0])|    (20,[2],[1.0])|(69,[0,1,11,29,33...|     350079.0737632893|\n",
      "+---+----------+---------+------------+--------------+--------------+------------+-------------------------+------------------------+-------------------------------+----------+---------------+------------------+----------------+--------------+-----------------+--------------------+------------------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test_df = lr.transform(test).withColumnRenamed('prediction', 'predicted_resale_price')\n",
    "pred_test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(predicted_resale_price=247241.81254870223, resale_price=232000.0),\n",
       " Row(predicted_resale_price=352425.65344206576, resale_price=265000.0)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_and_actuals = pred_test_df[['predicted_resale_price', 'resale_price']]\n",
    "\n",
    "predictions_and_actuals_rdd = predictions_and_actuals.rdd\n",
    "predictions_and_actuals_rdd.take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(247241.81254870223, 232000.0), (352425.65344206576, 265000.0)]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_and_actuals_rdd = predictions_and_actuals_rdd.map(tuple)\n",
    "predictions_and_actuals_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[296], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegressionMetrics\n\u001b[1;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m RegressionMetrics(predictions_and_actuals_rdd)\n\u001b[1;32m      4\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mMean Squared Error:         \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mRoot Mean Squared Error:    \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mMean Absolute Error:        \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mR**2:                       \u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;241m.\u001b[39mformat(metrics\u001b[38;5;241m.\u001b[39mmeanSquaredError, metrics\u001b[38;5;241m.\u001b[39mrootMeanSquaredError, metrics\u001b[38;5;241m.\u001b[39mmeanAbsoluteError, metrics\u001b[38;5;241m.\u001b[39mr2)\n",
      "File \u001b[0;32m~/Documents/GitHub/Distributed-Machine-Learning-with-Spark/spark_mllib/lib/python3.12/site-packages/pyspark/mllib/evaluation.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrdd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RDD\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JavaModelWrapper, callMLlibFunc\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matrix\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLContext\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayType, DoubleType, StructField, StructType\n",
      "File \u001b[0;32m~/Documents/GitHub/Distributed-Machine-Learning-with-Spark/spark_mllib/lib/python3.12/site-packages/pyspark/mllib/linalg/__init__.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m since\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg \u001b[38;5;28;01mas\u001b[39;00m newlinalg\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     UserDefinedType,\n\u001b[1;32m     36\u001b[0m     StructField,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     BooleanType,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     46\u001b[0m     Any,\n\u001b[1;32m     47\u001b[0m     Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     Union,\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Distributed-Machine-Learning-with-Spark/spark_mllib/lib/python3.12/site-packages/pyspark/ml/__init__.py:31\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     Estimator,\n\u001b[1;32m     24\u001b[0m     Model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     UnaryTransformer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline, PipelineModel\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     classification,\n\u001b[1;32m     33\u001b[0m     clustering,\n\u001b[1;32m     34\u001b[0m     evaluation,\n\u001b[1;32m     35\u001b[0m     feature,\n\u001b[1;32m     36\u001b[0m     fpm,\n\u001b[1;32m     37\u001b[0m     image,\n\u001b[1;32m     38\u001b[0m     recommendation,\n\u001b[1;32m     39\u001b[0m     regression,\n\u001b[1;32m     40\u001b[0m     stat,\n\u001b[1;32m     41\u001b[0m     tuning,\n\u001b[1;32m     42\u001b[0m     util,\n\u001b[1;32m     43\u001b[0m     linalg,\n\u001b[1;32m     44\u001b[0m     param,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchDistributor\n\u001b[1;32m     48\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnaryTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchDistributor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/GitHub/Distributed-Machine-Learning-with-Spark/spark_mllib/lib/python3.12/site-packages/pyspark/ml/image.py:31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, NoReturn, Optional, cast\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Row, StructType, _create_row, _parse_datatype_json_string\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "metrics = RegressionMetrics(predictions_and_actuals_rdd)\n",
    "s = '''\n",
    "Mean Squared Error:         {0}\n",
    "Root Mean Squared Error:    {1}\n",
    "Mean Absolute Error:        {2}\n",
    "R**2:                       {3}\n",
    "'''.format(metrics.meanSquaredError, metrics.rootMeanSquaredError, metrics.meanAbsoluteError, metrics.r2)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_mllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
